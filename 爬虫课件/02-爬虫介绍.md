- 什么是爬虫？

  网络爬虫（又被称为网页蜘蛛，网络机器人）, 是一种按照一定的规则，自动地抓取万维网信息的程序或者脚本。

- 获取数据几种途径

  - 用户产生数据   [百度指数](http://index.baidu.com/#/)
  - 数据平台购买数据 [聚合数据](https://www.juhe.cn/docs/api/id/39?s=bd1003)
  - 政府公开数据 [统计局数据](http://data.stats.gov.cn/index.htm)

- 爬虫的作用

  - 数据分析
  - 购物助手
  - 咨询网站
  - 搜索引擎

- 需要知识

  - Python 基础知识
  - HTML 基础知识
  - 数据持久化知识
  - Scrapy框架知识

- 爬虫的分类

  - 通用爬虫

    - ![](http://tp.jikedaohang.com/20191028102604_meDo0p_5b8d4423d9052.jpeg)
    - 通用网络爬虫 是 捜索引擎抓取系统（Baidu、Google、Yahoo等）的重要组成部分。主要目的是将互联网上的网页下载到本地，形成一个互联网内容的镜像备份。

  - 聚焦爬虫

    - 聚焦爬虫，是"面向特定主题需求"的一种网络爬虫程序，它与通用搜索引擎爬虫的区别在于： 　

  - 不同

    -  聚焦爬虫在实施网页抓取时会对内容进行处理筛选，尽量保证只抓取与需求相关的网页信息。

    

- Robots协议

  全称是“网络爬虫排除标准”（Robots Exclusion Protocol），网站通过Robots协议告诉搜索引擎哪些页面可以抓取，哪些页面不能抓取，

  例如：https://www.jd.com/robots.txt

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  
  
  